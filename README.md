ğŸ§ Penguin AI Prediction Project

This project predicts the species of a penguin based on its physical characteristics. A trained machine learning model is used to generate daily predictions, which are stored in a JSON file and displayed on a simple frontend.

ğŸš€ Project Overview

Utilizes a Random Forest model to classify penguin species.

GitHub Actions automation updates predictions daily at 7:30 AM.

SQLite database stores penguin data.

Frontend: A static HTML page fetches and displays daily predictions.

Optional Streamlit App: Allows users to input penguin features for real-time classification.

ğŸ“‚ Project Structure

BDS_2025_M4_Exercise_1/
â”‚â”€â”€ .github/workflows/        # GitHub Actions workflows
â”‚   â”œâ”€â”€ fetch_and_predict.yml  # Automates daily data fetching and predictions
â”‚
â”‚â”€â”€ data/                     # Data storage
â”‚   â”œâ”€â”€ penguins.db            # SQLite database containing penguin data
â”‚   â”œâ”€â”€ penguin_prediction.json # Daily updated JSON with the latest prediction
â”‚
â”‚â”€â”€ models/                   # Trained model and preprocessing tools
â”‚   â”œâ”€â”€ model.pkl              # Random Forest model
â”‚   â”œâ”€â”€ le.pkl                 # Label encoder
â”‚   â”œâ”€â”€ scaler.pkl             # Scaler for feature normalization
â”‚
â”‚â”€â”€ src/                      # Python scripts for data processing and modeling
â”‚   â”œâ”€â”€ data_to_db.py          # Converts raw data into SQLite database
â”‚   â”œâ”€â”€ train_model.py         # Trains the ML model
â”‚   â”œâ”€â”€ predict_penguin.py     # Generates daily predictions
â”‚
â”‚â”€â”€ index.html                 # Frontend webpage displaying predictions
â”‚â”€â”€ README.md                   # Project documentation
â”‚â”€â”€ requirements.txt            # Dependencies

âš™ï¸ How It Works

1ï¸âƒ£ Data Processing

data_to_db.py processes the raw penguin dataset and stores it in penguins.db.

2ï¸âƒ£ Model Training

train_model.py trains a Random Forest classifier to predict penguin species.

The trained model is stored in models/model.pkl.

3ï¸âƒ£ Daily Predictions (Automated via GitHub Actions)

fetch_and_predict.yml runs every morning to:

Fetch the latest penguin data.

Use predict_penguin.py to generate a new prediction.

Save the prediction to data/penguin_prediction.json.

4ï¸âƒ£ Frontend Display

The index.html file fetches penguin_prediction.json and displays the latest prediction using JavaScript.

ğŸ“¦ Installation & Setup

1ï¸âƒ£ Clone the Repository

git clone https://github.com/your-username/BDS_2025_M4_Exercise_1.git
cd BDS_2025_M4_Exercise_1

2ï¸âƒ£ Install Dependencies

pip install -r requirements.txt

3ï¸âƒ£ Prepare the Database

python src/data_to_db.py

4ï¸âƒ£ Train the Model (Only Needed for Retraining)

python src/train_model.py

5ï¸âƒ£ Generate a Prediction

python src/predict_penguin.py

ğŸŒ Hosting the Frontend with GitHub Pages

To host index.html using GitHub Pages:

Move index.html to the docs/ directory

In GitHub:

Go to Settings > Pages.

Set the source branch to main and folder to /docs.

Click "Save" to deploy.

Your project will be available at:

https://your-username.github.io/BDS_2025_M4_Exercise_1/

ğŸ“Œ Notes

penguin_prediction.json is updated automatically every day, so avoid manual modifications.

The frontend fetches the JSON file from /data/penguin_prediction.json, so ensure it exists.

ğŸ›  Future Improvements

Improve model accuracy with additional training data.

Add a Streamlit backend for real-time input predictions.

Enhance the UI for a better user experience.

ğŸš€ Happy Coding! ğŸ§